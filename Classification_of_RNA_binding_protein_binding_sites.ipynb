{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "name": " Classification of RNA-binding protein binding sites.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deaAxcLV63JQ",
        "colab_type": "text"
      },
      "source": [
        "# Classification of RNA-binding protein binding sites\n",
        "## Lecture 'ML methods for biological sequence classification'\n",
        "### Annalisa Marsico and Ernesto Elorduy, TUM 29.01.2020\n",
        "\n",
        "The goal of this tutorial is to help you familiarize yourself with the use of **S**upport **V**ector **M**achines (SVMs) for classification tasks. Especially the second exercise is meant to show you how SVMs can be used in combination with string kernels to classify biological RNA sequences corresponding to RNA-binding protein sites.\n",
        "\n",
        "Metazoan genomes encode hundreds of **R**NA-**b**inding **p**roteins (RBPs). These proteins regulate post-transcriptional gene expression and have critical roles in numerous cellular processes including mRNA splicing, export, stability and translation. Despite their ubiquity and importance, the binding preferences for most RBPs are not well characterized. \n",
        "\n",
        "High-throughput techniques, such as CLIP-seq experiments (cross-linking immunoprecipitation followed by high-throughput sequencing) allow the genome-wide characterization of RNA-binding protein sites. CLIP-seq experiments employ *’peak-calling’* methods to identify clusters of read coverage that are significantly enriched above background. These clusters can then be classified as *’binding sites’*. This raises some questions: \n",
        "- *Can RNA-binding protein sites be discriminated from other RNA regions (or background transcripts) based on sequence alone?* \n",
        "- *Which sequence features are enriched in such binding sites for a particular protein under study?* \n",
        "\n",
        "In this tutorial we provide fasta sequences of the putative binding sites for two proteins: IGF2BP123 and PUM2. These RBPs are known to be involved in RNA regulation and bind to mRNAs as well as long non-coding RNAs.\n",
        "\n",
        "The original data was been downloaded from [this database](http://dorina.mdc-berlin.de), converted to fasta files and pre-processed in our lab. Negative/background regions were generated by taking random genomic regions corresponding to transcribed RNAs, maintaining the same length distribution as the binding site sequences. Links for downloading these data sets are provided below.\n",
        "\n",
        "We will split this classification into the following subtasks:\n",
        "1. Loading the data\n",
        "2. Calculating the spectra\n",
        "3. Doing a train and test split of the sequences\n",
        "4. Performing a grid search to find good choices for $\\mathrm{C}$ and $\\mathrm{k}$\n",
        "5. Extracting the most important k-mers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDMSXhve7KdE",
        "colab_type": "text"
      },
      "source": [
        "Install Biopython"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jh4xibDq7BEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install biopython"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyn3Hx4Ay_yU",
        "colab_type": "text"
      },
      "source": [
        "Import modules and set matplotlib's backend"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvPMhfPG63JU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import Bio.SeqIO as sio\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "from sklearn.metrics import precision_recall_curve, precision_score\n",
        "from sklearn.metrics import average_precision_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn\n",
        "import itertools\n",
        "import operator\n",
        "%matplotlib inline\n",
        "\n",
        "got_time = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvA56CDZGNt4",
        "colab_type": "text"
      },
      "source": [
        "Download the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSYafH2zAgoQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We prefix the \"!\" character to run bash commands in IPython\n",
        "!wget -O positive_IGF2BP123.fasta -nv https://hmgubox.helmholtz-muenchen.de/f/845665a7cdd4495aa7db/?dl=1\n",
        "!wget -O negative_IGF2BP123.fasta -nv https://hmgubox.helmholtz-muenchen.de/f/3947aa537280430bb15b/?dl=1\n",
        "!wget -O positive_PUM2.fasta -nv https://hmgubox.helmholtz-muenchen.de/f/99a7578b298545da86f5/?dl=1\n",
        "!wget -O negative_PUM2.fasta -nv https://hmgubox.helmholtz-muenchen.de/f/2b82b3e15ac24197ad84/?dl=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCa_Lt6b63Jo",
        "colab_type": "text"
      },
      "source": [
        "## 1. Loading the data\n",
        "_Biopython_ makes loading fasta sequences easy.\n",
        "Here we use `sio.parse()` on our fasta file. It returns an iterable `SeqRecord` object which we can itarate over, e. g. with a for loop or a comprehension, to construct lists of sequences. \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX-5DwL3DEcL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Choose one RBP (IGF2BP123 or PUM2) and create a list of sequences for each of \n",
        "# the positive and negative data sets.\n",
        "pos_seqs = # your code here \n",
        "neg_seqs = # your code here "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db0TldsMeADJ",
        "colab_type": "text"
      },
      "source": [
        "Have a look at one of the sequences. Notice that binding site sequences are shown in upper case in the fasta ﬁle and that  sequences ﬂanking the binding sites are displayed in lower case. \n",
        "\n",
        "- Are flanking sequences crucial for our classiﬁcation task?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xR1GQ3XQAht3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Have a look at the ouput of sio.parse()\n",
        "print(type(pos_seqs[0]))\n",
        "print(pos_seqs[0].seq)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v45i7jFi63Jz",
        "colab_type": "text"
      },
      "source": [
        "## 2. Calculating the spectrum of each sequence\n",
        "The general idea is to find a solution that maps a sequence to a vector. In a standard **spectrum kernel**, the vector contains a dimension for each k-mer and therefore:\n",
        "\n",
        "$\\begin{equation}\n",
        "\\phi(x_i) \\in \\mathbb{R}^{4^k}\n",
        "\\end{equation}$\n",
        "\n",
        "From an applied point of view, this implies that reasonable choices for $\\mathrm{k}$ should not be too large as the vectors are very sparse and can explode in size quickly.\n",
        "\n",
        "- Try to understand the code below and how the spectrum kernel has been implemented.\n",
        "\n",
        "- *For the ambitious of you: have a look at [sparse vectors](https://docs.scipy.org/doc/scipy/reference/sparse.html) and see if that you can improve performance or memory. However, this is not mandatory.* (\\*)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYUfc1Ie63J2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_numbers_for_sequence(sequence):\n",
        "    result = []\n",
        "    for letter in sequence:\n",
        "        if letter == 'A':\n",
        "            result.append(0)\n",
        "        elif letter == 'C':\n",
        "            result.append(1)\n",
        "        elif letter == 'G':\n",
        "            result.append(2)\n",
        "        elif letter == 'T' or letter == 'U':\n",
        "            result.append(3)\n",
        "        else:\n",
        "            return [-1]\n",
        "    return result\n",
        "\n",
        "def _extract_spectrum_sequence(sequence, k):\n",
        "    \"\"\"Compute k-spectrum for a given sequence and k-mer length k.\n",
        "\n",
        "    This method computes the spectrum for a given sequence and k-mer-length k.\n",
        "    The idea is to first create a vector of the given size (4**k) and then\n",
        "    transform each k-mer to a sequence of length k of numbers 0-3\n",
        "    (0 = A, 1 = C, 2 = G, 3 = U).\n",
        "    From there, we can multiply that sequence with a vector of length k,\n",
        "    containing the exponents of 4 to calculate the position in the spectrum.\n",
        "    Example: AUUC -> 0331 -> 4**0*1 + 4**1*3 + 4**2*3 + 4**3*0\n",
        "    \"\"\"\n",
        "    n = len(sequence)\n",
        "    spectrum = np.zeros(np.power(4, k))\n",
        "    multiplier = np.power(4, range(k))[::-1]\n",
        "    for pos in range(n - k + 1):\n",
        "        pos_in_spectrum = np.sum(multiplier * get_numbers_for_sequence(sequence[pos:pos+k]))\n",
        "        spectrum[pos_in_spectrum] += 1\n",
        "    return spectrum\n",
        "\n",
        "def extract_spectrum(sequences, k, include_flanking=False):\n",
        "    \"\"\"Compute k-spectra for a set of sequences using k-mer length k.\n",
        "    \n",
        "    Computes the k-spectra for a set of sequences. This is done such that the\n",
        "    resulting vectors can be fed into a linear SVM or other classification\n",
        "    algorithm. The k-spectrum of a sequence is a sparse vector containing the\n",
        "    number of times that a k-mer occurs in the given sequence. It has\n",
        "    as many dimensions as there are possible k-mers.\n",
        "    \n",
        "    Parameters:\n",
        "    ----------\n",
        "    sequences:              A list of Biopython sequences\n",
        "    k:                      Integer. The length of kmers to consider\n",
        "    include_flanking:       Include flanking regions? (the lower-case letters\n",
        "                            in the sequences given)\n",
        "    \n",
        "    Returns:\n",
        "    -------\n",
        "    A numpy array of shape (N, 4**k), containing the k-spectrum for each\n",
        "    sequence. N is the number of sequences and k the length of k-mers considered.\n",
        "    \"\"\"\n",
        "    spectrum = []\n",
        "    for seq in sequences:\n",
        "        if include_flanking:\n",
        "            seq = seq.upper()\n",
        "        else:\n",
        "            seq = [x for x in seq if 'A' <= x <= 'Z']\n",
        "        spectrum.append(_extract_spectrum_sequence(seq, k))\n",
        "    return np.array(spectrum)\n",
        "\n",
        "class SpectrumSVM:\n",
        "    \"\"\"\n",
        "    This builds a wrapper for the spectrum calculation and SVM classifier\n",
        "    to support tuning the parameters via grid search.\n",
        "    \"\"\"\n",
        "    def __init__(self, C=1, k=3, include_flanking=False):\n",
        "        self.C = C\n",
        "        self.k = k\n",
        "        self.include_flanking = include_flanking\n",
        "        self.clf = SVC(C=self.C, probability=True, kernel='linear')\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        spectrum_X = extract_spectrum(X, self.k, self.include_flanking)\n",
        "        self.clf.fit(spectrum_X, y)\n",
        "    \n",
        "    def predict_proba(self, X):\n",
        "        spectrum_X = extract_spectrum(X, self.k, self.include_flanking)\n",
        "        return self.clf.predict_proba(spectrum_X)\n",
        "\n",
        "    def predict(self, X):\n",
        "        spectrum_X = extract_spectrum(X, self.k, self.include_flanking)\n",
        "        return self.clf.predict(spectrum_X)\n",
        "\n",
        "    def set_params(self, **parameters):\n",
        "        for parameter, value in parameters.items():\n",
        "            setattr(self, parameter, value)\n",
        "        return self\n",
        "\n",
        "    def get_params(self,deep=True):\n",
        "        return {\"C\" : self.C, \"k\" : self.k,\"include_flanking\" : self.include_flanking}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhT4-_J263J_",
        "colab_type": "text"
      },
      "source": [
        "### Test if spectra are correct and plot which k-mers are over-represented"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XY5jNBoG63KC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "k = 3\n",
        "start = time.time()\n",
        "spectrum_pos = extract_spectrum(pos_seqs, k, include_flanking=False)\n",
        "spectrum_neg = extract_spectrum(neg_seqs, k, include_flanking=False)\n",
        "print (\"Calculated {}-spectrum in {} seconds\".format(k, time.time() - start))\n",
        "\n",
        "list_of_kmers = map(''.join, itertools.product('ACGU', repeat=k))\n",
        "fig = plt.figure(figsize=(14, 8))\n",
        "ind = range(4**k)\n",
        "ax = plt.barh(ind, np.mean(spectrum_pos, axis=0) - np.mean(spectrum_neg, axis=0))\n",
        "y = plt.yticks(ind, list_of_kmers, fontsize=6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKfFQhoD63KL",
        "colab_type": "text"
      },
      "source": [
        "## 3. Perform a Training and Test split\n",
        "[scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html?highlight=train%20test#sklearn.model_selection.train_test_split) provides us with the function `train_test_split()` to divide our data into random train and test subsets. This is necessary to see how our model generalizes on previously 'unseen' data.\n",
        "\n",
        "- Create a train-test split of the feature and target variables. \n",
        "- Use a test size of 0.1, and a random state of 42 to ensure reproducibility.\n",
        "\n",
        "Be sure to do a proper [stratification](https://stats.stackexchange.com/questions/49540/understanding-stratified-cross-validation) of your data. This will help us ensure that our random sample is well balanced (same/similar distribution of classes in both the train and test sets), which reduces estimation errors. Remember that with a simple random split, we may end with a non-representative distribution of our target classes in the test set. \n",
        "\n",
        "*Even if we are presented with a balanced dataset, stratification won't harm. It is a good practice to apply stratification on all our train-test splits.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slef5Y1o63KN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a train-test split of the feature and target variables. \n",
        "# Use a test size of 0.1, and a random state of 42 for reproducibility.\n",
        "# Hint: start by creating the feature and target variables by concatenating \n",
        "# class labes and the spectra created before.\n",
        "\n",
        "y = # your code here\n",
        "X = # your code here\n",
        "\n",
        "X_train, X_test, y_train, y_test = # your code here\n",
        "\n",
        "print (X_train.shape, X_test.shape)\n",
        "print (y_train.shape, y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojdgOYcq63KS",
        "colab_type": "text"
      },
      "source": [
        "## 4. Hyperparameter Tuning\n",
        "In order to extract good hyperparameters, a grid search trying out all combinations of parameters in some defined ranges can be performed. For this, [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV) provides the function `GridSearchCV()` which optimizes hyperparameters of the estimator by searching through a custom hyperparameter grid for the best cross validation score.\n",
        "\n",
        "We already performed this tuning and found following parameter candidates: `{'k': 5, 'C': 0.1, 'include_flanking': False}`.\n",
        "\n",
        "- Intantiate a support vector classifier and fit a model based on the previously split training data.\n",
        "- *For the ambitious of you: try tuning the hyperparameters $\\mathrm{k}$, $\\mathrm{C}$, and $\\mathrm{include\\_flanking}$ by yourself. Have a look at [this example](https://hmgubox.helmholtz-muenchen.de/f/b1d7b638edc2420ea3cb/?dl=1). **Warning:** depending on the number of CV runs as well as the size of the parameter grid selected,* `GridSearchCV()` *might take very long computation times. Alternatively,* `RandomizedSearchCV()` *can be used to save computation resources. This is not mandatory.* (\\*)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaWz_jf963KV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# best params are {'k': 5, 'C': 0.1, 'include_flanking': False}\n",
        "start = time.time()\n",
        "clf = SVC(C=0.1, kernel='linear', probability=True)\n",
        "clf.fit(X_train, y_train)\n",
        "print (\"Trained linear SVM on {}-spectrum in {} seconds\".format(k, time.time() - start))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-9AI4s263Kc",
        "colab_type": "text"
      },
      "source": [
        "### Performance Evaluation\n",
        "Let's have a look at how well we are doing on the test data. Accuracy is a valid metric as we are dealing with a balanced data set, but let's also look at ROC and PR curves."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qwgo091Z63Kd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# how well are we doing on the test set\n",
        "y_score = clf.predict_proba(X_test)\n",
        "roc_auc = roc_auc_score(y_score=y_score[:,1], y_true=y_test)\n",
        "tpr, fpr, _ = roc_curve(y_score=y_score[:,1], y_true=y_test)\n",
        "fig = plt.figure(figsize=(14, 8))\n",
        "plt.plot(tpr, fpr, label='Performance Spectrum Kernel (AUC: {:0.2f})'.format(roc_auc),\n",
        "         lw=4, color='orange')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=4, linestyle='--', label='random')\n",
        "plt.legend(loc='lower right')\n",
        "print (\"Test Set ROC-AUC: {}\".format(roc_auc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRsi7V-463Ki",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pr_auc = average_precision_score(y_score=y_score[:,1], y_true=y_test)\n",
        "pr, rc, _ = precision_recall_curve(y_test, y_score[:,1])\n",
        "fig = plt.figure(figsize=(14, 8))\n",
        "plt.plot(rc, pr, label='Performance Spectrum Kernel (AUC: {:0.2f})'.format(pr_auc),\n",
        "         lw=4, color='orange')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.plot([0, 1], [0.5, 0.5], color='navy', lw=4, linestyle='--', label='Random')\n",
        "plt.ylim([0, 1.05])\n",
        "plt.legend(loc='upper right')\n",
        "print (\"Test Set PR-AUC: {}\".format(pr_auc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEKzXPMU63Ko",
        "colab_type": "text"
      },
      "source": [
        "## 5. Extracting the most important k-mers\n",
        "Now that we have optimal parameters and are sure that our algorithm does reasonably well on the test data, let's have a look at the most relevant k-mers. \n",
        "\n",
        "- Do they make sense from a biological point of view?\n",
        "  - Search the literature for known information about the binding motif of the analyzed RBP.\n",
        "\n",
        "- Which features (k-mers) contribute the most to discriminate real binding sites from background regions?\n",
        "  - Find the important features by extracting the weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTKxaeUo63Kr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_of_kmers = map(''.join, itertools.product('ACGT', repeat=k))\n",
        "coefs_sorted, kmers_sorted = zip(*sorted(zip(clf.coef_.reshape(-1), list_of_kmers),\n",
        "  key=operator.itemgetter(0), reverse=True))\n",
        "\n",
        "max_kmers = 50\n",
        "fig = plt.figure(figsize=(20, 10))\n",
        "ind = range(min(clf.coef_.shape[1], max_kmers))\n",
        "ax = plt.bar(ind, coefs_sorted[:max_kmers])\n",
        "x = plt.xticks(ind, kmers_sorted[:max_kmers], rotation=45)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}